## Training with 5 layers - LSTM:
## Data: Tuda, M-AILABS, Common Voice

Training Summary Epoch: [1]     Time taken (s): 18      Average Loss 39.725
Validation Summary Epoch: [1]   Average WER 61.286      Average CER 16.690
Learning rate annealed to: 0.000273

Validation Summary Epoch: [2]   Average WER 46.4

Training Summary Epoch: [3]     Time taken (s): 8918    Average Loss 22.291
Validation Summary Epoch: [3]   Average WER 40.663      Average CER 10.190
Learning rate annealed to: 0.000248

Training Summary Epoch: [4]     Time taken (s): 672     Average Loss 18.209
Validation Summary Epoch: [4]   Average WER 34.519      Average CER 8.456
Learning rate annealed to: 0.000225

Validation Summary Epoch: [5]	Average WER 32.162	Average CER 7.801	
Learning rate annealed to: 0.000205

Validation Summary Epoch: [6]	Average WER 29.811	Average CER 7.368	
Learning rate annealed to: 0.000186

Validation Summary Epoch: [7]	Average WER 28.487	Average CER 6.903	
Learning rate annealed to: 0.000169

Validation Summary Epoch: [8]   Average WER 27.907      Average CER 6.927
Learning rate annealed to: 0.000154

Validation Summary Epoch: [9]	Average WER 26.624	Average CER 6.543	
Learning rate annealed to: 0.000140

Validation Summary Epoch: [10]  Average WER 27.005      Average CER 6.662
Learning rate annealed to: 0.000127

Validation Summary Epoch: [11]  Average WER 26.004      Average CER 6.413
Learning rate annealed to: 0.000116

Validation Summary Epoch: [12]	Average WER 25.658	Average CER 6.320	
Learning rate annealed to: 0.000105

Validation Summary Epoch: [13]	Average WER 25.499	Average CER 6.282	
Learning rate annealed to: 0.000096

Training Summary Epoch: [14]    Time taken (s): 5119    Average Loss 1.784
Validation Summary Epoch: [14]  Average WER 25.802      Average CER 6.350


#Added movies data, single-speaker data, --augment flag
Training Summary Epoch: [14]    Time taken (s): 3166    Average Loss 9.937
Validation Summary Epoch: [14]  Average WER 24.956      Average CER 6.132
Learning rate annealed to: 0.000096

Training Summary Epoch: [15]    Time taken (s): 16671   Average Loss 9.399
Validation Summary Epoch: [15]  Average WER 24.554      Average CER 6.032

Training Summary Epoch: [16]	Time taken (s): 30435	Average Loss 8.603
Validation Summary Epoch: [16]	Average WER 23.290	Average CER 5.703

Training Summary Epoch: [17]	Time taken (s): 40969	Average Loss 8.051
Validation Summary Epoch: [17]	Average WER 23.610	Average CER 5.840	
Learning rate annealed to: 0.000072

****************************************
#Test Results after Epoch 8:
#Without Language Model (Greedy Decoder) - Test Set = Tuda + Common Voice:
Test Summary    Average WER 34.337      Average CER 9.160

#Without Language Model (Greedy Decoder) - Test Set = Tuda only:
Test Summary    Average WER 42.813      Average CER 11.761



#With Language Model: 
# 3-gram LM, beam-width 10, alpha 0.9, beta 0.3 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 22.191      Average CER 12.094

# 3-gram LM, beam-width 10, alpha 1.0, beta 0.8 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 22.752      Average CER 12.602

# 3-gram LM, beam-width 10, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 22.377      Average CER 12.217

# 3-gram LM, beam-width 20, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 17.992      Average CER 9.305

# 3-gram LM, beam-width 30, alpha 0.9, beta 0.3 - Test Set = Tuda only:
Test Summary    Average WER 22.984      Average CER 11.765

# 3-gram LM, beam-width 50, alpha 0.9, beta 0.3 - Test Set = Tuda only:
Test Summary    Average WER 20.947      Average CER 10.455

# 3-gram LM, beam-width 100, alpha 0.9, beta 0.3 - Test Set = Tuda only:
Test Summary    Average WER 18.890      Average CER 9.222

[====Using SRILM====]
(ngram-count to create both lm for mary and train, and ngram -mix-lm with different weights to mary)

# 4-gram LM (0.1*Mary) , beam-width 20, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 28.246  Average CER 11.314

# 4-gram LM (0.2,3,4*Mary) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 26.870      Average CER 8.882

# 4-gram LM (0.8*Mary, 0.2*train) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 26.870      Average CER 8.882

# 4-gram LM (train only) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 29.947      Average CER 9.362



[====Using KENLM====]
# 4-gram LM (Mary+train) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.781      Average CER 7.341

# 6-gram LM (Mary+train) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.795      Average CER 7.342

# 4-gram LM (Mary+10*train) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.805      Average CER 7.352

# 4-gram LM (Mary+train) , beam-width 150, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.466      Average CER 7.085

# 4-gram LM (Mary+10*train) , beam-width 150, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.496      Average CER 7.098

# 4-gram LM (Mary+train) , beam-width 200, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:	
Test Summary    Average WER 19.273      Average CER 6.941	

# 4-gram LM (Mary+train) , beam-width 250, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:	
Test Summary    Average WER 19.172      Average CER 6.854	

# 4-gram LM (Mary+train) , beam-width 350, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:	
Test Summary    Average WER 19.003      Average CER 6.727

# 4-gram LM (Mary) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.989      Average CER 7.377

# 4-gram LM (Mary) , beam-width 200, alpha 0.9, beta 0.2 - Test Set = Tuda:
Test Summary    Average WER 26.797      Average CER 9.858

# 4-gram LM (Mary+train+ 5_million_web+ Wiki) , beam-width 350, alpha 0.9, beta 0.2 - Test Set = Tuda:
Test Summary    Average WER 24.712      Average CER 9.323

# 4-gram LM (Mary+train+ 5_million_web+ Wiki) , beam-width 100, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 19.092      Average CER 7.301

# 4-gram LM (Mary+train+ 5_million_web+ Wiki) , beam-width 350, alpha 0.9, beta 0.2 - Test Set = Tuda + Common Voice:
Test Summary    Average WER 17.831      Average CER 6.552

****************************************

##############################################################################

## Training with 3 layers - GRU:
## Data: Tuda, M-AILABS, Common Voice


Validation Summary Epoch: [1]   Average WER 67      Average CER 19
Validation Summary Epoch: [2]   Average WER 57      Average CER 17
Training Summary Epoch: [3]     Time taken (s): 5594    Average Loss 24.363
Validation Summary Epoch: [3]   Average WER 53.292      Average CER 15.158
Learning rate annealed to: 0.000273
Training Summary Epoch: [4]     Time taken (s): 24111    Average Loss 19.688
Validation Summary Epoch: [4]   Average WER 50.643      Average CER 14.3
Learning rate annealed to: 0.000248
Training Summary Epoch: [5]     Time taken (s): 3117    Average Loss 16.492
Validation Summary Epoch: [5]   Average WER 48.801      Average CER 13.397
Learning rate annealed to: 0.000225
Average Loss Approx 10
Validation Summary Epoch: [6]   Average WER 45.637      Average CER 12.471
Training Summary Epoch: [7]     Time taken (s): 7967    Average Loss 9.806
Validation Summary Epoch: [7]   Average WER 47.341      Average CER 13.092